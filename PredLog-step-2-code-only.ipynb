{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "pd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded.shape"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['message'][2695]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "len(df_downloaded[df_downloaded.message == 'spp-vsnap.cristie.se (Vsnap): free disk space 266,815 MB (16.32% free) lower than threshold 20%.'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# df[df['A'].str.contains(\"hello\")]\n#len(df_downloaded[df_downloaded['message'].str.contains('lower than threshold')]) => 600\n\npd.set_option('display.max_colwidth', -1)\n\ndf_lower=df_downloaded[df_downloaded['message'].str.contains('lower than threshold')]\ndf_lower['message']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['message'][44]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['message'][130]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['message']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['initMessageParams']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sublist = df_downloaded['initMessageParams'][0]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sublist"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(sublist[0])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded['categoryDisplayName'].unique()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#iter_df = df_downloaded['initMessageParams']\n#df_downloaded['_unitLevel'] = \"\"\n#for unitlevellist in iter_df:\n#    #print(unitlevellist[0])\n#    #print(iter_df)\n#    unitlevel = unitlevellist[0]\n#    df_downloaded._unitLevel = unitlevel\n\n#for index, row in iter_df.iteritems():\n    #print(index, row[0])  # debug\n    #print(df_downloaded.iloc[index]) # debug\n    #df_downloaded.iloc[index]._unitLevel = row[0]\n    #print(df_downloaded.iloc[index]._unitLevel)\n    #print(\"****************************************************\")  # debug"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n\n\n# 'True' if x <= 4 else 'False'\n\n#df_downloaded.assign(_unitLevel= 'Foo' if df_downloaded['initMessageParams'] == 'None' else df_downloaded['initMessageParams'][0])\ndf_downloaded['_unitLevel'] = df_downloaded['initMessageParams'].apply(lambda x: 'Foo' if x == 'None' else x[0])\n#df['name_match'] = df['First_name'].apply(lambda x: 'Match' if x == 'Bill' else 'Mis-Match')\n\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# OK, now we have an extra column called _unitLevel with the unit and level sorted out"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Save to object storage in new file: "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# feature engineering and select the important ones\n\ndf_reduced=df_downloaded_new[['acknowledged', 'alertTime', 'category', 'categoryDisplayName', 'count', 'dataSource','expired','expiresAt', 'first', 'initMessageParams','initialMessage','jobSessionId', 'last','message', 'messageName','messageParams','name','retention','status','statusDisplayName','storageId','type','typeDisplayName','unique', '_unitLevel']]\n#print(df_reduced.head())\n#print(df_reduced.shape)\ndf_reduced=df_reduced.dropna()\n#df_reduced=df_reduced['_unitLevel'].drop_values('Foo','CertSrv1','Win2016Test', 'win2016-test','vmware_Templates','Report_1004_1000','Report_1003_1000','Report_1002_1000','Hypervisor Inventory', 'Deploy1', '_unitLevel','ubuntohog','Maintenance')\nmask = df_reduced['_unitLevel'].isin(['Report_License','_unitLevel', 'Foo','CertSrv1','Win2016Test', 'win2016-test','vmware_Templates','Report_1004_1000','Report_1003_1000','Report_1002_1000','Hypervisor Inventory', 'Deploy1', '_unitLevel','ubuntuhog','Maintenance', 'Report_1005_1000','vmware_DLN_PROTECT01','vmware_DLN_TEST_DELETE_IN_JUNE2019',95.61194610595703,95.1344985961914, 95.78414916992188, 95.00507354736328,'Report_wtg','Report_1014_1000','Report_1015_1000','Report_1013_1000',95.17405700683594, 'Report_1012_1000','Report_1011_1000','Report_1001_1000',95.12422943115234, 95.47147369384766, 95.41291809082031,'onDemandRestore_1568284281377'])\ndf_reduced=df_reduced[~mask]\n\nprint(df_reduced.head())\nprint(df_reduced['_unitLevel'].unique())\n#print(df_reduced.shape)\n# save as csv in project for future use\n#print(df_reduced.describe())\ndf_reduced.to_csv('./example_log_data.csv')\nclient_cred.upload_file('./example_log_data.csv', bucket, 'df_example_log.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new['_unitLevel']"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new['_unitLevel'].unique()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "len(df_downloaded_new['_unitLevel'].unique())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_unitMessages=df_downloaded_new[['_unitLevel', 'messageName']]\n\ndf_sumOfMessagesPerUnit=pd.DataFrame(df_unitMessages.groupby(['_unitLevel', 'messageName']).size())\n#df_unitMessages.groupby(['_unitLevel', 'messageName']).size()\n\n#df.groupby('A').B.agg(['count']).rename(columns={'count': 'foo'})\n\ndf_test = df_downloaded_new.groupby(['_unitLevel', 'messageName']).agg(['count'])\ndf_test.head(25)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# rename 0 column to sum\n# df.rename({'a': 'X', 'b': 'Y'}, axis=1, inplace=True)\ndf_sumOfMessagesPerUnit.rename(columns={0: \"SUM\"}, inplace=True)\n\ndf_sumOfMessagesPerUnit"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#df.sort_values(by=['col1'])\ndf_sumOfMessagesPerUnit.sort_values(by=['SUM'], ascending=False)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new[df_downloaded_new['messageName'] == 'None'].message"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "backup_msg=pd.DataFrame(df_downloaded_new[df_downloaded_new['messageName'] == 'None'].message)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "backup_msg.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "len(backup_msg['message'].unique())"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": false
            },
            "outputs": [],
            "source": "#len(backup_msg['message']) => 171\nbackup_msg"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "backup_msg['message'].unique()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "felet, frekv., antal, klustring => action"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Let's work on the timings and add a column for \"last seen\""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# with cred to https://stackoverflow.com/questions/51856844/python-pandas-minutes-since-last-occurrence-in-2-million-row-dataframe\n\ndf_downloaded_new.alertTime = pd.to_datetime(df_downloaded_new.alertTime)\n#df_downloaded_new.head(10)\ndf_downloaded_new['minDiff'] = (df_downloaded_new.alertTime -df_downloaded_new.alertTime.shift(1)).astype('timedelta64[m]')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "df_downloaded_new.head(10)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "the_mess1 = 'Log backup failed for database [WideWorldImporters] on instance [SQL2016]. An exception occurred while executing a Transact-SQL statement or batch.. Error: 0x80131501'\nmask1 = (df_downloaded_new.message == the_mess1).cumsum().shift(1)\n\n#print(mask1)\n\nthe_mess2 = 'Log backup failed for database [AdventureWorks2014] on instance [SQL2016]. An exception occurred while executing a Transact-SQL statement or batch.. Error: 0x80131501'\nmask2 = (df_downloaded_new.message == the_mess2).cumsum().shift(1)\n#print(mask2)\ndf_downloaded_new['minDiffMess1'] = df_downloaded_new.groupby(mask1.where(mask1 > 0)).minDiff.cumsum()\ndf_downloaded_new['minDiffMess2'] = df_downloaded_new.groupby(mask2.where(mask2 > 0)).minDiff.cumsum()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#df_downloaded_new.minDiffMess = df_downloaded_new.minDiffMess.replace(0,method='ffill')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new.head(25)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_Mess=df_downloaded_new[df_downloaded_new['name'] == 'SQLLOG_ALERT_MESSAGE']\ndf_Mess=df_Mess[(df_Mess['message'] == the_mess1) | (df_Mess['message'] == the_mess2)]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_Mess[['alertTime','message','name','minDiffMess1','minDiffMess2']]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from datetime import datetime\n\nlast_time=datetime(2019,1,1,0,0)\n#print(last_time)\nprint(type(last_time))\ndef add_time(t):\n    global last_time\n    t_delta=t\n    #print(type(t))\n    t_delta= t-last_time\n    #t_delta = (last_time-t).astype('timedelta64[m]')\n    last_time = t\n    print(t_delta)\n    return t_delta\n\n#df_downloaded_new['_lastSeen'] = df_downloaded_new['message'].apply(lambda x: add_time(df_downloaded_new['alertTime'].values) if x == the_mess1 else 0)\ndf_downloaded_new['_lastSeen'] = df_downloaded_new.apply(lambda row: add_time(row['alertTime']) if row['message'] == the_mess1 else 0, axis=1)\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#mess_array=df_downloaded_new['message'].unique()\n#df_Foo=df_downloaded_new[df_downloaded_new['_unitLevel'] == 'Foo'] #vmware_Gold hyperv_Bronze catalog_Bronze sql_Bronze vmware_Bronze\ndf_Foo=df_downloaded_new[df_downloaded_new['_unitLevel'].isin(['Foo', 'vmware_Gold', 'hyperv_Bronze', 'catalog_Bronze', 'sql_Bronze', 'vmware_Bronze'])]\n#print(df_Foo)\nmess_array=df_Foo['_unitLevel'].unique()\n#mess_array=['Log backup failed for database [WideWorldImporters] on instance [SQL2016]. An exception occurred while executing a Transact-SQL statement or batch.. Error: 0x80131501',\n#            'Log backup failed for database [AdventureWorks2014] on instance [SQL2016]. An exception occurred while executing a Transact-SQL statement or batch.. Error: 0x80131501',\n#            'Job vmware_Gold (id=1009, session=1,553,346,300,231) partially succeeded.']\nprint(len(mess_array))\nmess_array = mess_array[:10]\nmess_array"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from datetime import datetime\nfrom datetime import timedelta\n\n\nlast_time=datetime(2019,3,23,13,5)\n#print(last_time)\nprint(type(last_time))\ndef add_time(t):\n    global last_time\n    t_delta=t\n    #print(type(t))\n    t_delta= abs(t-last_time)\n    #t_delta = (last_time-t).astype('timedelta64[m]')\n    last_time = t\n    #print(t_delta)\n    #delta = timedelta(days=t_delta.days, hours=t_delta.hours, minutes=t_delta.minutes, seconds=t_delta.seconds)\n    total_seconds = t_delta.total_seconds()\n    minutes = int(total_seconds // 60)\n    #print(type(minutes))\n    t_delta=minutes\n    return t_delta\n\ndef test_row(t,m,l):\n    global messx\n    if (m == messx):\n        print('Found match!')\n        return add_time(t)\n    else :\n        return l\n    \nfor messx in mess_array:\n    print(messx)\n    last_time=datetime(2019,3,23,13,5)\n    for label, row in df_downloaded_new.iterrows():\n        print(label)\n        df_downloaded_new.loc[label, '_lastSeen'] = test_row(row['alertTime'], row['_unitLevel'], row['_lastSeen'])\n        print(df_downloaded_new.loc[label, '_lastSeen'])\n        #df_downloaded_new['_lastSeen'] = df_downloaded_new.apply(lambda row: add_time(row['alertTime']) if row['message'] == mess else 0, axis=1)\n    "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_downloaded_new.head(50)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# feature engineering and select the important ones\n\n#df_reduced_2=df_downloaded_new[['acknowledged', 'alertTime', 'category', 'categoryDisplayName', 'count', 'dataSource','expired','expiresAt', 'first', 'initMessageParams','initialMessage','jobSessionId', 'last','message', 'messageName','messageParams','name','retention','status','statusDisplayName','storageId','type','typeDisplayName','unique', '_unitLevel', '_lastSeen']]\ndf_reduced_2=df_downloaded_new[['acknowledged', 'alertTime', 'category', 'categoryDisplayName', 'count', 'dataSource','expired','expiresAt', 'first', 'initMessageParams','initialMessage','jobSessionId', 'last','message', 'messageName','messageParams','name','retention','status','statusDisplayName','storageId','type','unique', '_unitLevel', '_lastSeen']]\n\n#print(df_reduced.head())\n#print(df_reduced.shape)\ndf_reduced_2=df_reduced_2.dropna()\n#df_reduced=df_reduced['_unitLevel'].drop_values('Foo','CertSrv1','Win2016Test', 'win2016-test','vmware_Templates','Report_1004_1000','Report_1003_1000','Report_1002_1000','Hypervisor Inventory', 'Deploy1', '_unitLevel','ubuntohog','Maintenance')\n#mask = df_reduced_2['_unitLevel'].isin(['Report_License','_unitLevel', 'Foo','CertSrv1','Win2016Test', 'win2016-test','vmware_Templates','Report_1004_1000','Report_1003_1000','Report_1002_1000','Hypervisor Inventory', 'Deploy1', '_unitLevel','ubuntuhog','Maintenance', 'Report_1005_1000','vmware_DLN_PROTECT01','vmware_DLN_TEST_DELETE_IN_JUNE2019',95.61194610595703,95.1344985961914, 95.78414916992188, 95.00507354736328,'Report_wtg','Report_1014_1000','Report_1015_1000','Report_1013_1000',95.17405700683594, 'Report_1012_1000','Report_1011_1000','Report_1001_1000',95.12422943115234, 95.47147369384766, 95.41291809082031,'onDemandRestore_1568284281377'])\nmask = df_reduced_2['_unitLevel'].isin(['Report_License','_unitLevel','CertSrv1','Win2016Test', 'win2016-test','vmware_Templates','Report_1004_1000','Report_1003_1000','Report_1002_1000','Hypervisor Inventory', 'Deploy1', '_unitLevel','ubuntuhog','Maintenance', 'Report_1005_1000','vmware_DLN_PROTECT01','vmware_DLN_TEST_DELETE_IN_JUNE2019',95.61194610595703,95.1344985961914, 95.78414916992188, 95.00507354736328,'Report_wtg','Report_1014_1000','Report_1015_1000','Report_1013_1000',95.17405700683594, 'Report_1012_1000','Report_1011_1000','Report_1001_1000',95.12422943115234, 95.47147369384766, 95.41291809082031,'onDemandRestore_1568284281377'])\n\ndf_reduced_2=df_reduced_2[~mask]\n\nprint(df_reduced_2.head())\nprint(df_reduced_2['_unitLevel'].unique())\n#print(df_reduced.shape)\n# save as csv in project for future use\n#print(df_reduced.describe())\n\ndf_reduced_2=df_reduced_2[df_reduced_2['name'] != 'SERVER_DOWN']\nprint(df_reduced_2['name'].unique())\n\ndf_reduced_2=df_reduced_2[df_reduced_2['name'] != 'VSNAP_STORAGE_SPACE_LOW']\nprint(df_reduced_2['name'].unique())\n\n\n \ndf_reduced_2.to_csv('./example_log_data_2.csv', index=False)\nclient_cred.upload_file('./example_log_data_2.csv', bucket, 'df_example_log_2.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "df_reduced_2[df_reduced_2['name']== 'SERVER_DOWN'].count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}